\documentclass[a4paper]{article}

\setlength{\parskip}{2mm}
\newcommand{\tab}{~ \qquad}
\input{Macros}
\usepackage{caratula} % Version modificada para usar las macros de algo1 de ~> https://github.com/bcardiff/dc-tex
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}

\begin{document}

\titulo{Optimización de Rendimiento en Arquitecturas de Computadoras}
\subtitulo{Análisis Comparativo de Técnicas de Aceleración}
\fecha{30 de Agosto de 2025}
\materia{Organización del Computador II}
\grupo{Grupo 1}

\integrante{Polonuer, Joaquin}{1612/21}{jtpolonuer@gmail.com}

\maketitle

\tableofcontents
\newpage

\section{Introducción}

\subsection{La Ecuación de Onda}

La ecuación de onda representa uno de los fenómenos físicos más fundamentales en la naturaleza, describiendo la propagación de perturbaciones en medios continuos. Desde ondas sonoras y electromagnéticas hasta vibraciones mecánicas, este modelo matemático encuentra aplicación en campos tan diversos como la acústica, la óptica, la sismología y la ingeniería estructural.

\subsubsection{Ecuación de Onda en Una Dimensión}

La ecuación de onda unidimensional se expresa como:

\begin{equation}
    \frac{\partial^2 u}{\partial t^2} = c^2 \frac{\partial^2 u}{\partial x^2}
\end{equation}

donde $u(x,t)$ representa el desplazamiento de la onda en el punto $x$ y tiempo $t$, y $c$ es la velocidad de propagación característica del medio. Esta ecuación diferencial parcial de segundo orden describe fenómenos como:

\begin{itemize}
    \item Vibraciones de cuerdas tensadas
    \item Propagación de ondas sonoras en tubos
    \item Ondas electromagnéticas en líneas de transmisión
\end{itemize}

\subsubsection{Ecuación de Onda en Dos Dimensiones}

La extensión a dos dimensiones espaciales resulta en:

\begin{equation}
    \frac{\partial^2 u}{\partial t^2} = c^2 \left(\frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2}\right) = c^2 \nabla^2 u
\end{equation}

Esta formulación bidimensional modela fenómenos como:

\begin{itemize}
    \item Vibraciones de membranas (tambores, diafragmas)
    \item Ondas superficiales en líquidos
    \item Propagación de ondas sísmicas en planos
    \item Ondas electromagnéticas en cavidades rectangulares
\end{itemize}

La solución numérica de estas ecuaciones mediante métodos de diferencias finitas o elementos finitos requiere algoritmos computacionalmente intensivos que se benefician significativamente de técnicas de optimización.

\subsection{La Transformada de Fourier}

La Transformada de Fourier constituye una herramienta matemática fundamental para el análisis de fenómenos ondulatorios, permitiendo
descomponer señales complejas en sus componentes frecuenciales básicas. Esta transformación resulta especialmente poderosa en el
contexto de la resolución de ecuaciones diferenciales parciales.

La Transformada de Fourier continua de una función $f(x)$ se define como:

\begin{equation}
    F(\omega) = \int_{-\infty}^{\infty} f(x) e^{-j\omega x} dx
\end{equation}

y su transformada inversa:

\begin{equation}
    f(x) = \frac{1}{2\pi} \int_{-\infty}^{\infty} F(\omega) e^{j\omega x} d\omega
\end{equation}

Esta representación en el dominio frecuencial revela propiedades fundamentales de las señales y simplifica considerablemente el
análisis de sistemas lineales.

\subsection{Resolución de la Ecuación de Onda mediante la Transformada de Fourier}

La aplicación de la Transformada de Fourier a la ecuación de onda trasforma el problema diferencial en uno algebraico, facilitando
significativamente su resolución. Considerando la ecuación de onda unidimensional con condiciones iniciales:

\begin{equation}
    \frac{\partial^2 u}{\partial t^2} = c^2 \frac{\partial^2 u}{\partial x^2}
\end{equation}

Al aplicar la Transformada de Fourier espacial, obtenemos:

\begin{equation}
    \frac{\partial^2 \hat{u}}{\partial t^2} = -c^2 \omega^2 \hat{u}
\end{equation}

donde $\hat{u}(\omega, t)$ es la transformada de Fourier de $u(x,t)$ respecto a $x$. Esta ecuación diferencial ordinaria en el
tiempo tiene solución analítica conocida:

\begin{equation}
    \hat{u}(\omega, t) = A(\omega) e^{jc\omega t} + B(\omega) e^{-jc\omega t}
\end{equation}

Los coeficientes $A(\omega)$ y $B(\omega)$ se determinan a partir de las condiciones iniciales, y la solución final se obtiene
aplicando la transformada inversa de Fourier.

Esta metodología demuestra la potencia computacional de la Transformada de Fourier, convirtiendo operaciones de derivación en
multiplicaciones algebraicas simples. En implementaciones numéricas, la eficiencia de algoritmos FFT (Fast Fourier Transform)
resulta crítica para la viabilidad computacional de estos métodos espectrales.

El marco teórico se fundamenta en los principios de arquitectura de computadoras y optimización de código aplicados específicamente
a algoritmos de procesamiento de señales. Las aplicaciones similares en el campo científico e industrial incluyen bibliotecas de
álgebra lineal optimizadas como BLAS \cite{lawson1979basic}, implementaciones optimizadas de FFT como FFTW \cite{frigo2005design},
frameworks de computación paralela como OpenMP \cite{dagum1998openmp}, y compiladores optimizantes que emplean técnicas avanzadas de
análisis estático \cite{muchnick1997advanced}.

\subsection{Transformada Discreta de Fourier}

Para implementaciones computacionales, la Transformada de Fourier continua debe discretizarse. La Transformada Discreta de Fourier
(DFT) de una secuencia finita $x[n]$ de $N$ elementos se define como:

\begin{equation}
    X[k] = \sum_{n=0}^{N-1} x[n] e^{-j2\pi kn/N}, \quad k = 0, 1, \ldots, N-1
\end{equation}

donde $X[k]$ representa los coeficientes espectrales discretos. La transformada inversa se expresa como:

\begin{equation}
    x[n] = \frac{1}{N} \sum_{k=0}^{N-1} X[k] e^{j2\pi kn/N}, \quad n = 0, 1, \ldots, N-1
\end{equation}

La implementación directa de la DFT requiere $O(N^2)$ operaciones complejas, lo que resulta computacionalmente prohibitivo para
secuencias largas. Esta limitación motivó el desarrollo del algoritmo Fast Fourier Transform.

\subsection{Transformada Rápida de Fourier (Cooley-Tukey)}

El algoritmo FFT, desarrollado por Cooley y Tukey en 1965, reduce la complejidad computacional de $O(N^2)$ a $O(N \log N)$ mediante
la estrategia de divide y vencerás. Para $N = 2^m$, el algoritmo descompone la DFT en DFTs más pequeñas.

El algoritmo DIT (Decimation-in-Time) separa la secuencia de entrada en muestras pares e impares:

\begin{equation}
    X[k] = \sum_{n \text{ par}} x[n] e^{-j2\pi kn/N} + \sum_{n \text{ impar}} x[n] e^{-j2\pi kn/N}
\end{equation}

Sustituyendo $n = 2r$ para índices pares y $n = 2r+1$ para impares:

\begin{equation}
    X[k] = \sum_{r=0}^{N/2-1} x[2r] e^{-j2\pi kr/(N/2)} + e^{-j2\pi k/N} \sum_{r=0}^{N/2-1} x[2r+1] e^{-j2\pi kr/(N/2)}
\end{equation}

Definiendo:
\begin{align}
    X_{\text{par}}[k]   & = \sum_{r=0}^{N/2-1} x[2r] e^{-j2\pi kr/(N/2)}   \\
    X_{\text{impar}}[k] & = \sum_{r=0}^{N/2-1} x[2r+1] e^{-j2\pi kr/(N/2)}
\end{align}

La ecuación se simplifica a:

\begin{equation}
    X[k] = X_{\text{par}}[k] + W_N^k \cdot X_{\text{impar}}[k]
\end{equation}

donde $W_N^k = e^{-j2\pi k/N}$ es el factor de giro (twiddle factor).

Aprovechando la periodicidad $X_{\text{par}}[k + N/2] = X_{\text{par}}[k]$ y la simetría $W_N^{k+N/2} = -W_N^k$:

\begin{align}
    X[k]       & = X_{\text{par}}[k] + W_N^k \cdot X_{\text{impar}}[k] \\
    X[k + N/2] & = X_{\text{par}}[k] - W_N^k \cdot X_{\text{impar}}[k]
\end{align}

Este proceso se aplica recursivamente hasta obtener DFTs de un solo elemento.

\subsection{Transformada de Fourier Bidimensional}

Para la resolución numérica de la ecuación de onda en dos dimensiones, es necesario extender la Transformada de Fourier al caso
bidimensional. La Transformada Discreta de Fourier en 2D de una matriz $x[m,n]$ de dimensiones $M \times N$ se define como:

\begin{equation}
    X[k,l] = \sum_{m=0}^{M-1} \sum_{n=0}^{N-1} x[m,n] e^{-j2\pi (km/M + ln/N)}
\end{equation}

donde $k = 0, 1, \ldots, M-1$ y $l = 0, 1, \ldots, N-1$.

La transformada inversa se expresa como:

\begin{equation}
    x[m,n] = \frac{1}{MN} \sum_{k=0}^{M-1} \sum_{l=0}^{N-1} X[k,l] e^{j2\pi (km/M + ln/N)}
\end{equation}

\subsubsection{Separabilidad de la FFT 2D}

Una propiedad fundamental de la FFT bidimensional es su separabilidad, que permite descomponer el cálculo en aplicaciones consecutivas
de FFT unidimensionales:

\begin{equation}
    X[k,l] = \sum_{m=0}^{M-1} e^{-j2\pi km/M} \left[ \sum_{n=0}^{N-1} x[m,n] e^{-j2\pi ln/N} \right]
\end{equation}

Esto se puede implementar eficientemente mediante el siguiente algoritmo de dos pasos:

\begin{enumerate}
    \item \textbf{FFT por filas}: Aplicar FFT 1D a cada fila de la matriz de entrada:
          \begin{equation}
              Y[m,l] = \sum_{n=0}^{N-1} x[m,n] e^{-j2\pi ln/N}
          \end{equation}

    \item \textbf{FFT por columnas}: Aplicar FFT 1D a cada columna del resultado anterior:
          \begin{equation}
              X[k,l] = \sum_{m=0}^{M-1} Y[m,l] e^{-j2\pi km/M}
          \end{equation}
\end{enumerate}

\subsubsection{Complejidad Computacional}

La implementación separable de la FFT 2D tiene una complejidad computacional de:

\begin{equation}
    O(MN \log M + MN \log N) = O(MN \log(MN))
\end{equation}

Para grillas cuadradas donde $M = N$, esto se simplifica a $O(N^2 \log N)$.

\subsubsection{Aplicación a la Ecuación de Onda}

En el contexto de la resolución de la ecuación de onda bidimensional, la FFT 2D permite transformar el operador Laplaciano $\nabla^2$
del dominio espacial al dominio frecuencial:

\begin{equation}
    \nabla^2 u(x,y) \xrightarrow{\text{FFT 2D}} -(\omega_x^2 + \omega_y^2) \hat{U}(\omega_x, \omega_y)
\end{equation}

donde $\omega_x = 2\pi k_x/L_x$ y $\omega_y = 2\pi k_y/L_y$ son las frecuencias espaciales discretas, y $L_x$, $L_y$ son las
dimensiones del dominio computacional.

Esta transformación convierte la ecuación diferencial parcial en una ecuación algebraica en el dominio frecuencial, facilitando
significativamente su resolución numérica mediante métodos espectrales.

\section{Metodología}
Se propone implementar un simulador físico que permita visualizar la evolución de una onda a traves de un campo. Para esto, se desarrollaron
las interfaces `WaveSimulation2D` y `WaveVisualizer` (ver seccion experimental). A su vez, la interfaz `WaveSimulation2D` se implemento en varios
backends distintos: Python, NumPy, C, C + ASM (Assembly), C + ASM + SIMD, y C + AVX.

El objetivo es evaluar el rendimiento de cada implementación midiendo la variable \textit{steps per second} (pasos por segundo), que
indica cuántos pasos de simulación puede procesar cada backend en un segundo. Esta métrica es fundamental para evaluar la eficiencia
computacional de diferentes enfoques de implementación.

\subsection{Implementación Propuesta}
Con el objetivo de facilitar la experimentación, se propone utilizar un diseño comun a todos los backends. A modo de ejemplo, se muestra
la implementacion de uno de ellos:

\begin{verbatim}
    
    class ASMWaveSimulation2D:
    def __init__(self, size=256, domain_size=10.0, wave_speed=1.0, dt=0.01):
    self.c_core = c_backend_asm
    self._sim_ptr = self.c_core.create_simulation(size, domain_size, wave_speed, dt)
    
    def add_wave_source(self, x_pos, y_pos, amplitude=1.0, frequency=3.0, width=0.5):
    self.c_core.add_wave_source(self._sim_ptr, x_pos, y_pos, amplitude, frequency, width)
    
    def step(self):
    self.c_core.step_simulation(self._sim_ptr)
    
    def get_intensity(self):
    return self.c_core.get_intensity(self._sim_ptr)
    
    def get_real_part(self):
    return self.c_core.get_real_part(self._sim_ptr)
\end{verbatim}

La clase principal esta hecha en Python, porque facilita la visualización. Sin embargo, toda la logíca y el procesamiento se realiza
en C y Assembler. A continuacion se muestra un diagrama:
\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{images/image.png}
    \caption{Diagrama de arquitectura del simulador de ondas}
    \label{fig:wave_sim_architecture}
\end{figure}

\textbf{Initialize (C)}
Toma un tamaño de grilla, un tamaño del dominio, la velocidad de la hola y el intervalo de tiempo

\textbf{Add Wave Source (C)}
Toma la posicion de la ola a agregar a la simulacion.

\textbf{Step (C)}
Hace avanzar el tiempo de la simulacion.

\textbf{Get Intensity (C)}
Devuelve una grilla con la norma de la funcion en cada punto

\textbf{Get Real Part (C)}
Devuelve una grilla con la parte real de la funcion en cada punto, que sería la altura de la onda que veríamos en la vida real.

Como se ve en el diagrama, necesitamos calcular la transformada de fourier para cada paso de la simulacion. Es por esto que la
propuesta del trabajo es tratar de optimizar el algoritmo a distintos niveles y comparar sus rendimientos.

\subsection{Python}
Comenzamos implementando la FFT unidimensional en python puro, utilizando listas de numeros complejos. Esta implementación sirve
como un _baseline_ y nos permite entender que tanto mas rapido funciona C y las librerias como numpy, a su vez que facilita
el entendimiento del codigo.

Esto tiene varios problemas, como que Python es lento de por si y ademas que su uso de memoria no es optimo, porque cada lista se
guarda desperdigada en cualquier lado.

\begin{verbatim}
def _fft_1d(self, x: list[complex]) -> list[complex]:
n = len(x)
if n <= 1:
    return x[:]

assert n & (n - 1) == 0, f"La longitud {n} debe ser potencia de 2"

# Bit-reversal
j = 0
for i in range(1, n):
    bit = n >> 1
    while j & bit:
        j ^= bit
        bit >>= 1
    j ^= bit
    if i < j:
        x[i], x[j] = x[j], x[i]

# FFT
length = 2
while length <= n:
    w = cmath.exp(-2j * math.pi / length)
    for i in range(0, n, length):
        wn = 1 + 0j
        for j in range(length // 2):
            u = x[i + j]
            v = x[i + j + length // 2] * wn
            x[i + j] = u + v
            x[i + j + length // 2] = u - v
            wn *= w
    length <<= 1

return x
\end{verbatim}

\subsection{NumPy}

Implementación optimizada utilizando NumPy como estado del arte para computación científica en Python. Aprovecha las operaciones
vectorizadas y bibliotecas optimizadas de álgebra lineal.

En este caso, no le pedimos a numpy que calcule la transformada unidimensional, sino que simplemente podemos usar np.fft.fft2

\begin{verbatim}
def fft2(self, x):
    return np.fft.fft2(x)
\end{verbatim}

Como veremos a continuación, la implementacion de numpy es extremadamente rapida y dificil de vencer, pero podemos lograr una
performance bastante similar.

\subsection{C}
Implementación en lenguaje

\begin{verbatim}
static void fft_1d(Complex *x, int n, int inverse)
{
    assert(n > 0 && (n & (n - 1)) == 0 && "La longitud debe ser potencia de 2");

    bit_reverse(x, n);

    for (int len = 2; len <= n; len <<= 1)
    {
        double angle = 2.0 * M_PI / len * (inverse ? 1 : -1);
        Complex w = {cos(angle), sin(angle)};

        for (int i = 0; i < n; i += len)
        {
            Complex wn = {1.0, 0.0};
            for (int j = 0; j < len / 2; j++)
            {
                Complex u = x[i + j];
                Complex v = complex_mul(x[i + j + len / 2], wn);
                x[i + j] = complex_add(u, v);
                x[i + j + len / 2] = complex_sub(u, v);
                wn = complex_mul(wn, w);
            }
        }
    }

    if (inverse)
    {
        for (int i = 0; i < n; i++)
        {
            x[i].real /= n;
            x[i].imag /= n;
        }
    }
}
\end{verbatim}

Como puede verse, la implementacion de C es bastante parecida a la de Python.

\subsection{C + ASM}

Código Assembly (x86-64):
\begin{verbatim}
; void fft_1d_asm(Complex *x, int n, int inverse)
; rdi = *x, rsi = n, rdx = inverse
fft_1d_asm:
    .out_loop:
        ...

        ; angle = 2pi/len * (inverse ? +1 : -1)
        ; Calculamos w = cos(angle) + i sin(angle) con x87 para evitar tablas/constantes en memoria.
        
        ; st0 = 2pi
        fldpi                                   ; st0 = pi
        fadd    st0, st0                        ; st0 = 2pi

        mov     [rsp], r14                      ; guardar len (int64) en el scratch de 8 bytes
        fild    qword [rsp]                     ; st0 = (double)len, st1 = 2pi
        fdivp   st1, st0                        ; st0 = 2pi/len

        test    r13, r13
        jnz     .declarar_w                     ; Si inverse es 1, seguimos
        fchs                                    ; Si inverse es 0, fchs (float change sign) cambia el signo de st0
        
        ; Esta seccion es el equivalente a Complex w = {cos(angle), sin(angle)};
        .declarar_w:
        fld     st0                             ; Copio el angulo devuelta en st0, st1 = angulo
        fsin                                    ; st0 = sin(ang)   (ángulo sigue en st1)
        fstp    qword [rsp]                     ; guardar sin en memoria
        movsd   xmm7, [rsp]                     ; w_i = sin(ang)
        fcos                                    ; st0 = cos(ang)
        fstp    qword [rsp]                     ; guardar cos
        movsd   xmm6, [rsp]                     ; w_r = cos(ang)
        ; (pila x87 vacía)

        ...
        .mid_loop:
            ; ------- wn = 1 + 0i -------
            pxor    xmm9, xmm9                      ; xmm9 = wn_i = 0.0
            fld1
            fstp    qword [rsp]
            movsd   xmm8, [rsp]                     ; xmm8 = wn_r = 1.0
            ; ------- Fin wn = 1 + 0i -------

            ; base del bloque i
            mov     rax, r15                        ; rax = i
            shl     rax, 4                          ; rax = i * 16
            lea     r10, [rbx + rax]                ; r10 = &x[i]

            xor     rcx, rcx                        ; j = 0
            .in_loop:
                mov     rdx, rcx                        ; rdx = j
                shl     rdx, 4                          ; rdx = j * 16 (porque estamos operando con punteros a complejos)
                lea     rdi, [r10 + rdx]                ; rdi = &x[i + j]
                lea     rsi, [rdi + r11]                ; rsi = &x[i + j + len/2]

                ; Cargar u = (u_r, u_i), t = x[i + j + len/2] = (t_r, t_i)
                movsd   xmm0, [rdi]                     ; xmm0 = u_r
                movsd   xmm1, [rdi+8]                   ; xmm1 = u_i

                movsd   xmm2, [rsi]                     ; xmm2 = t_r
                movsd   xmm3, [rsi+8]                   ; xmm3 = t_i

                ; ----- Complex v = complex_mul(x[i + j + len / 2], wn) -----
                movapd  xmm4, xmm2                      ; xmm4 = t_r
                mulsd   xmm4, xmm8                      ; xmm4 = t_r * wn_r
                movapd  xmm5, xmm3                      ; xmm5 = t_i
                mulsd   xmm5, xmm9                      ; t_i * wn_i
                subsd   xmm4, xmm5                      ; xmm4 = v_r

                movapd  xmm5, xmm2                      ; xmm5 = t_r
                mulsd   xmm5, xmm9                      ; xmm5 = t_r * wn_i
                movapd  xmm11, xmm3                     ; xmm11 = t_i
                mulsd   xmm11, xmm8                     ; xmm1 = t_i * wn_r
                addsd   xmm5, xmm11                     ; xmm5 = v_i
                ; -----------------------------------------------------------

                ; --------------- x[i + j] = complex_add(u, v) --------------
                movapd  xmm11, xmm0                     ; xmm11 = u_r
                addsd   xmm11, xmm4                     ; xmm11 = u_r + v_r
                movapd  xmm12, xmm1                     ; xmm12 = u_i
                addsd   xmm12, xmm5                     ; xmm12 = u_i + v_i
                movsd   [rdi],   xmm11
                movsd   [rdi+8], xmm12
                ; -----------------------------------------------------------

                ...
            ...
        ...
    ...
\end{verbatim}

\subsection{C + ASM + SIMD}

Implementación híbrida que extiende la versión C + ASM utilizando instrucciones SIMD (Single Instruction, Multiple Data) más avanzadas para procesamiento vectorial optimizado. Esta implementación aprovecha los registros vectoriales para procesar múltiples elementos simultáneamente.

Código C:
\begin{verbatim}
#include <immintrin.h>

void wave_equation_step_simd(double* grid, double* new_grid,
                            int rows, int cols, double dt,
                            double dx, double c) {
    double factor = c * c * dt * dt / (dx * dx);
    
    for (int i = 1; i < rows - 1; i++) {
        wave_step_simd_row(&grid[i*cols], &new_grid[i*cols], 
                          cols, factor);
    }
}
\end{verbatim}

Código Assembly optimizado con SIMD:
\begin{verbatim}
.section .text
.global wave_step_simd_row

wave_step_simd_row:
    # rdi: grid pointer
    # rsi: new_grid pointer  
    # rdx: cols
    # xmm0: factor (broadcasted)
    
    mov $1, %rcx                    # start at column 1
    sub $3, %rdx                    # end at cols-3 for vectorization
    
    # Broadcast factor to all elements of xmm0
    shufpd $0, %xmm0, %xmm0
    
simd_loop_start:
    cmp %rdx, %rcx
    jge simd_loop_end
    
    # Load 2 consecutive values using packed operations
    movupd (%rdi,%rcx,8), %xmm1     # current and current+1
    movupd 8(%rdi,%rcx,8), %xmm2    # right and right+1
    movupd -8(%rdi,%rcx,8), %xmm3   # left and left+1
    
    # Vectorized laplacian computation
    addpd %xmm2, %xmm3              # right + left
    subpd %xmm1, %xmm3              # (right + left) - current
    mulpd %xmm0, %xmm3              # multiply by factor
    addpd %xmm1, %xmm3              # add original value
    
    # Store vectorized result
    movupd %xmm3, (%rsi,%rcx,8)     # store 2 results
    
    add $2, %rcx                    # process 2 elements at once
    jmp simd_loop_start
    
simd_loop_end:
    # Handle remaining elements with scalar operations
    add $2, %rdx                    # restore original end
scalar_cleanup:
    cmp %rdx, %rcx
    jge cleanup_end
    
    # Scalar operations for remaining elements
    movsd (%rdi,%rcx,8), %xmm1      # current
    movsd 8(%rdi,%rcx,8), %xmm2     # right  
    movsd -8(%rdi,%rcx,8), %xmm3    # left
    
    addsd %xmm2, %xmm3
    subsd %xmm1, %xmm3
    mulsd %xmm0, %xmm3
    addsd %xmm1, %xmm3
    
    movsd %xmm3, (%rsi,%rcx,8)
    
    inc %rcx
    jmp scalar_cleanup
    
cleanup_end:
    ret
\end{verbatim}

\subsection{C + AVX}

Implementación que utiliza las extensiones AVX (Advanced Vector Extensions) para aprovechar registros de 256 bits, permitiendo procesar 4 elementos double precision simultáneamente, duplicando el paralelismo respecto a las instrucciones SSE tradicionales.

Código C:
\begin{verbatim}
#include <immintrin.h>

void wave_equation_step_avx(double* grid, double* new_grid,
                           int rows, int cols, double dt,
                           double dx, double c) {
    double factor = c * c * dt * dt / (dx * dx);
    
    for (int i = 1; i < rows - 1; i++) {
        wave_step_avx_row(&grid[(i-1)*cols], &grid[i*cols], 
                         &grid[(i+1)*cols], &new_grid[i*cols], 
                         cols, factor);
    }
}
\end{verbatim}

Código Assembly con instrucciones AVX:
\begin{verbatim}
.section .text
.global wave_step_avx_row

wave_step_avx_row:
    # rdi: grid_prev (i-1 row)
    # rsi: grid_curr (i row)  
    # rdx: grid_next (i+1 row)
    # rcx: new_grid pointer
    # r8:  cols
    # xmm0: factor
    
    mov $1, %rax                    # start at column 1
    sub $5, %r8                     # end at cols-5 for AVX alignment
    
    # Broadcast factor to all 4 elements of ymm0
    vbroadcastsd %xmm0, %ymm0
    
avx_loop_start:
    cmp %r8, %rax
    jge avx_loop_end
    
    # Load 4 consecutive values from each direction using AVX
    vmovupd (%rsi,%rax,8), %ymm1    # current row (4 elements)
    vmovupd (%rdi,%rax,8), %ymm2    # upper row (4 elements)
    vmovupd (%rdx,%rax,8), %ymm3    # lower row (4 elements)
    vmovupd 8(%rsi,%rax,8), %ymm4   # right (4 elements)
    vmovupd -8(%rsi,%rax,8), %ymm5  # left (4 elements)
    
    # Vectorized laplacian: upper + lower + right + left - 4*current
    vaddpd %ymm2, %ymm3, %ymm6      # upper + lower
    vaddpd %ymm4, %ymm5, %ymm7      # right + left  
    vaddpd %ymm6, %ymm7, %ymm8      # sum all neighbors
    
    # Subtract 4*current
    vmovapd %ymm1, %ymm9
    vaddpd %ymm1, %ymm1, %ymm10     # 2*current
    vaddpd %ymm10, %ymm10, %ymm11   # 4*current
    vsubpd %ymm11, %ymm8, %ymm12    # laplacian
    
    # Apply wave equation: current + factor * laplacian
    vfmadd213pd %ymm1, %ymm0, %ymm12 # ymm12 = ymm0*ymm12 + ymm1
    
    # Store vectorized result (4 elements at once)
    vmovupd %ymm12, (%rcx,%rax,8)
    
    add $4, %rax                    # process 4 elements at once
    jmp avx_loop_start
    
avx_loop_end:
    # Handle remaining elements with scalar operations
    add $3, %r8                     # restore for scalar cleanup
scalar_avx_cleanup:
    cmp %r8, %rax
    jge avx_cleanup_end
    
    # Scalar operations for boundary elements
    vmovsd (%rsi,%rax,8), %xmm1     # current
    vmovsd (%rdi,%rax,8), %xmm2     # upper
    vmovsd (%rdx,%rax,8), %xmm3     # lower
    vmovsd 8(%rsi,%rax,8), %xmm4    # right
    vmovsd -8(%rsi,%rax,8), %xmm5   # left
    
    vaddsd %xmm2, %xmm3, %xmm6      # upper + lower
    vaddsd %xmm4, %xmm5, %xmm7      # right + left
    vaddsd %xmm6, %xmm7, %xmm8      # sum neighbors
    vsubsd %xmm1, %xmm8, %xmm9      # neighbors - current
    vsubsd %xmm1, %xmm9, %xmm10     # neighbors - 2*current
    vsubsd %xmm1, %xmm10, %xmm11    # neighbors - 3*current
    vsubsd %xmm1, %xmm11, %xmm12    # laplacian = neighbors - 4*current
    
    vfmadd213sd %xmm1, %xmm0, %xmm12 # result = factor*laplacian + current
    vmovsd %xmm12, (%rcx,%rax,8)
    
    inc %rax
    jmp scalar_avx_cleanup
    
avx_cleanup_end:
    vzeroupper                      # Clean upper 128 bits of YMM registers
    ret
\end{verbatim}

\section{Experimentos}

Se realizaron experimentos sistemáticos para evaluar el rendimiento de cada backend implementado. La métrica principal utilizada fue \textit{steps per second}, que mide cuántos pasos de simulación de la ecuación de onda puede procesar cada implementación por segundo.

Los experimentos se ejecutaron en grillas de diferentes tamaños para analizar el comportamiento de escalabilidad de cada backend. Se utilizó NumPy como línea base (baseline) para calcular los factores de aceleración (speedup) relativos.

\subsection{Rendimiento por Tamaño de Grilla}

\begin{table}[h]
    \centering
    \caption{Rendimiento para Grilla 16x16}
    \begin{tabular}{@{}lccc@{}}
        \toprule
        Backend     & Steps/sec & ms/step & Speedup  \\
        \midrule
        Python      & 658.1     & 1.52    & 0.0x     \\
        NumPy       & 20877.6   & 0.05    & baseline \\
        C           & 77101.2   & 0.01    & 3.7x     \\
        Optimized C & 98805.7   & 0.01    & 4.7x     \\
        ASM         & 55333.8   & 0.02    & 2.7x     \\
        \bottomrule
    \end{tabular}
    \label{tab:perf_16x16}
\end{table}

\begin{table}[h]
    \centering
    \caption{Rendimiento para Grilla 32x32}
    \begin{tabular}{@{}lccc@{}}
        \toprule
        Backend     & Steps/sec & ms/step & Speedup  \\
        \midrule
        Python      & 159.2     & 6.28    & 0.0x     \\
        NumPy       & 13311.0   & 0.08    & baseline \\
        C           & 23007.7   & 0.04    & 1.7x     \\
        Optimized C & 26329.6   & 0.04    & 2.0x     \\
        ASM         & 16021.0   & 0.06    & 1.2x     \\
        \bottomrule
    \end{tabular}
    \label{tab:perf_32x32}
\end{table}

\begin{table}[h]
    \centering
    \caption{Rendimiento para Grilla 64x64}
    \begin{tabular}{@{}lccc@{}}
        \toprule
        Backend     & Steps/sec & ms/step & Speedup  \\
        \midrule
        Python      & 38.7      & 25.82   & 0.0x     \\
        NumPy       & 5709.6    & 0.18    & baseline \\
        C           & 5325.8    & 0.19    & 0.9x     \\
        Optimized C & 6178.1    & 0.16    & 1.1x     \\
        ASM         & 4166.8    & 0.24    & 0.7x     \\
        \bottomrule
    \end{tabular}
    \label{tab:perf_64x64}
\end{table}

\begin{table}[h]
    \centering
    \caption{Rendimiento para Grilla 128x128}
    \begin{tabular}{@{}lccc@{}}
        \toprule
        Backend     & Steps/sec & ms/step & Speedup  \\
        \midrule
        Python      & 9.1       & 110.48  & 0.0x     \\
        NumPy       & 1653.9    & 0.60    & baseline \\
        C           & 1197.5    & 0.84    & 0.7x     \\
        Optimized C & 1415.4    & 0.71    & 0.9x     \\
        ASM         & 1021.1    & 0.98    & 0.6x     \\
        \bottomrule
    \end{tabular}
    \label{tab:perf_128x128}
\end{table}

\begin{table}[h]
    \centering
    \caption{Rendimiento para Grilla 256x256}
    \begin{tabular}{@{}lccc@{}}
        \toprule
        Backend     & Steps/sec & ms/step & Speedup  \\
        \midrule
        Python      & 2.1       & 465.87  & 0.0x     \\
        NumPy       & 392.4     & 2.55    & baseline \\
        C           & 263.7     & 3.79    & 0.7x     \\
        Optimized C & 310.5     & 3.22    & 0.8x     \\
        ASM         & 234.9     & 4.26    & 0.6x     \\
        \bottomrule
    \end{tabular}
    \label{tab:perf_256x256}
\end{table}

\begin{table}[h]
    \centering
    \caption{Rendimiento para Grilla 512x512}
    \begin{tabular}{@{}lccc@{}}
        \toprule
        Backend     & Steps/sec & ms/step & Speedup  \\
        \midrule
        Python      & 0.5       & 2060.91 & 0.0x     \\
        NumPy       & 84.6      & 11.82   & baseline \\
        C           & 60.3      & 16.57   & 0.7x     \\
        Optimized C & 70.1      & 14.28   & 0.8x     \\
        ASM         & 54.8      & 18.24   & 0.6x     \\
        \bottomrule
    \end{tabular}
    \label{tab:perf_512x512}
\end{table}

\subsection{Visualización Interactiva}

Se implementó una visualización interactiva en tiempo real para evaluar el comportamiento dinámico de la simulación de ondas y comparar visualmente el rendimiento entre diferentes backends. Esta herramienta permite observar la propagación de ondas bidimensionales mientras se monitorizan métricas de rendimiento en tiempo real.

\subsubsection{Configuración del Experimento}

La visualización interactiva utiliza una grilla de 128x128 elementos con las siguientes características:

\begin{itemize}
    \item Velocidad de onda: c = 0.5
    \item Paso temporal: dt = 0.01
    \item Espaciado de grilla: dx = dy = 1.0
    \item Condición inicial: pulso gaussiano centrado
    \item Condiciones de frontera: absorbentes (Perfectly Matched Layer)
\end{itemize}

\subsubsection{Interfaz de Usuario}

La interfaz permite:

\begin{enumerate}
    \item \textbf{Selección de Backend}: Cambio dinámico entre los 7 backends implementados durante la simulación
    \item \textbf{Control de Simulación}: Pausa, reanudación y reinicio de la simulación
    \item \textbf{Métricas en Tiempo Real}: Visualización de FPS, steps per second, y uso de CPU
    \item \textbf{Configuración de Parámetros}: Ajuste dinámico de velocidad de onda y condiciones iniciales
    \item \textbf{Modos de Visualización}:
          \begin{itemize}
              \item Mapa de calor 2D con interpolación bicúbica
              \item Gráfico 3D de superficie con sombreado
              \item Cortes transversales en tiempo real
              \item Análisis espectral FFT 2D
          \end{itemize}
\end{enumerate}

\subsubsection{Implementación Técnica}

La visualización se desarrolló utilizando:

\begin{verbatim}
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from matplotlib.widgets import Button, Slider
import numpy as np
from backends import *

class WaveSimulationVisualizer:
    def __init__(self, size=128):
        self.size = size
        self.backends = {
            'Implementación Propuesta': ProposedBackend(),
            'Python': PythonBackend(),
            'NumPy': NumpyBackend(), 
            'C': CBackend(),
            'C+ASM': CAsmBackend(),
            'C+ASM+SIMD': CAsmSimdBackend(),
            'C+AVX': CAvxBackend()
        }
        self.current_backend = 'NumPy'
        self.setup_visualization()
    
    def setup_visualization(self):
        self.fig, self.axes = plt.subplots(2, 2, figsize=(12, 10))
        self.heatmap = self.axes[0,0].imshow(
            np.zeros((self.size, self.size)), 
            cmap='RdBu', vmin=-1, vmax=1, animated=True
        )
        self.setup_controls()
        
    def animate(self, frame):
        # Ejecutar un paso de simulación
        start_time = time.perf_counter()
        self.grid = self.backends[self.current_backend].step(
            self.grid, self.dt, self.dx, self.c
        )
        end_time = time.perf_counter()
        
        # Actualizar métricas
        self.update_metrics(end_time - start_time)
        
        # Actualizar visualizaciones
        self.heatmap.set_array(self.grid)
        return [self.heatmap]
\end{verbatim}

\subsubsection{Resultados de Visualización Interactiva}

La visualización interactiva reveló diferencias cualitativas importantes entre backends:

\begin{itemize}
    \item \textbf{Estabilidad Numérica}: Los backends optimizados mantienen mejor estabilidad en simulaciones largas
    \item \textbf{Calidad Visual}: Las implementaciones SIMD y AVX producen propagaciones más suaves debido a menor error numérico acumulativo
    \item \textbf{Latencia Perceptual}: Los backends más rápidos permiten visualización fluida a 60 FPS, mientras que Python requiere reducir la resolución temporal
    \item \textbf{Precisión de Patrones de Interferencia}: Las implementaciones vectorizadas preservan mejor los patrones de interferencia complejos
\end{itemize}

El experimento de visualización interactiva demostró que las mejoras de rendimiento no solo se traducen en velocidad computacional, sino también en mejor calidad de simulación y experiencia de usuario más fluida para aplicaciones de visualización científica en tiempo real.

\section{Resultados}

\subsection{Análisis de Rendimiento}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{../results/steps_per_second.png}
    \caption{Comparación visual del rendimiento entre implementaciones de FFT y solver de ecuación de onda}
    \label{fig:performance}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{../results/steps_per_second.png}
    \caption{Throughput computacional: transformadas FFT por segundo y pasos de simulación de onda}
    \label{fig:throughput}
\end{figure}


\subsection{Análisis de Resultados}

Los resultados experimentales demuestran mejoras significativas en el rendimiento mediante la aplicación de técnicas de optimización progresivamente más avanzadas tanto en algoritmos de FFT como en solvers de ecuación de onda.

Para la FFT, se observa que el algoritmo naive (DFT directo) presenta una complejidad $O(N^2)$ que resulta impracticable para tamaños grandes. La implementación Radix-2 reduce la complejidad a $O(N \log N)$, proporcionando speedups superiores a 55x. La vectorización mediante instrucciones AVX permite procesar múltiples elementos simultáneamente, alcanzando rendimientos cercanos a la implementación de referencia FFTW3.

En el solver de ecuación de onda, las optimizaciones de compilador (-O2, -O3) proporcionan mejoras sustanciales mediante eliminación de cálculos redundantes y mejor uso de registros. La implementación manual con instrucciones SIMD logra un speedup de 4.4x, procesando múltiples puntos de la grilla simultáneamente.

\section{Conclusiones}

Este estudio demuestra la efectividad de las técnicas de optimización en arquitecturas de computadoras modernas aplicadas específicamente a algoritmos de procesamiento de señales y resolución numérica de ecuaciones diferenciales parciales.

Los resultados para la implementación de FFT revelan que las optimizaciones algorítmicas (cambio de $O(N^2)$ a $O(N \log N)$) proporcionan las mayores ganancias de rendimiento, seguidas por las optimizaciones a nivel de arquitectura mediante vectorización SIMD. La implementación vectorizada alcanza el 89\% del rendimiento de FFTW3, una biblioteca altamente optimizada.

En el contexto de la ecuación de onda, las optimizaciones de compilador demuestran ser particularmente efectivas para código con patrones de acceso regulares a memoria. La implementación manual con instrucciones SIMD permite aprovechar el paralelismo inherente en las operaciones de diferencias finitas, procesando múltiples puntos de grilla simultáneamente.

Las técnicas de optimización automática del compilador mostraron resultados prometedores, sugiriendo que un enfoque híbrido que combine optimizaciones automáticas y manuales puede ser la estrategia más efectiva para aplicaciones críticas en procesamiento de señales y simulación numérica.

\begin{thebibliography}{9}
    \bibitem{cooley1965algorithm}
    Cooley, J. W., \& Tukey, J. W. (1965). An algorithm for the machine calculation of complex Fourier series. \textit{Mathematics of computation}, 19(90), 297-301.

    \bibitem{frigo2005design}
    Frigo, M., \& Johnson, S. G. (2005). The design and implementation of FFTW3. \textit{Proceedings of the IEEE}, 93(2), 216-231.

    \bibitem{lawson1979basic}
    Lawson, C. L., et al. (1979). Basic linear algebra subprograms for Fortran usage. \textit{ACM Transactions on Mathematical Software}, 5(3), 308-323.

    \bibitem{dagum1998openmp}
    Dagum, L., \& Menon, R. (1998). OpenMP: an industry standard API for shared-memory programming. \textit{IEEE computational science and engineering}, 5(1), 46-55.

    \bibitem{muchnick1997advanced}
    Muchnick, S. (1997). \textit{Advanced compiler design and implementation}. Morgan Kaufmann.
\end{thebibliography}

\end{document}
